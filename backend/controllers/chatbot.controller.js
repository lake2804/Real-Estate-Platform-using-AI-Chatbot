const openaiService = require('../services/openai.service');
const ragService = require('../services/rag.service');

console.log('ðŸ¤– Loading enhanced chatbot controller with OpenAI + RAG...');

// In-memory conversation storage
const conversations = new Map();

const chat = async (req, res) => {
  try {
    console.log('ðŸ’¬ Chat request received (OpenAI + RAG):', {
      body: req.body,
      hasMessage: !!req.body.message,
      hasQuery: !!req.body.query
    });

    const { message, query, conversation_id, user_id } = req.body;
    const userMessage = query || message;

    if (!userMessage?.trim()) {
      return res.status(400).json({
        success: false,
        message: 'Tin nháº¯n khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng',
        data: {
          response: 'â“ Vui lÃ²ng nháº­p cÃ¢u há»i Ä‘á»ƒ tÃ´i cÃ³ thá»ƒ tÆ° váº¥n báº¥t Ä‘á»™ng sáº£n dá»±a trÃªn phÃ¡p luáº­t hiá»‡n hÃ nh.',
          confidence: 0.0,
          sources: ['Validation Error'],
          conversationId: conversation_id || `conv_${Date.now()}`,
          timestamp: new Date().toISOString(),
          category: 'input_validation',
          provider: 'System'
        }
      });
    }

    const conversationId = conversation_id || `conv_${user_id || 'anonymous'}_${Date.now()}`;
    const conversationHistory = conversations.get(conversationId) || [];
    
    console.log('ðŸ” Processing with OpenAI + RAG:', {
      message: userMessage.substring(0, 50) + '...',
      conversationId,
      historyLength: conversationHistory.length,
      openaiHealth: openaiService.isHealthy(),
      ragHealth: ragService.isHealthy()
    });

    // Check OpenAI service
    if (!openaiService.isHealthy()) {
      console.error('âŒ OpenAI service not available');
      return res.status(503).json({
        success: false,
        message: 'Dá»‹ch vá»¥ AI khÃ´ng kháº£ dá»¥ng',
        data: {
          response: 'ðŸ”§ Há»‡ thá»‘ng AI hiá»‡n khÃ´ng kháº£ dá»¥ng. Vui lÃ²ng kiá»ƒm tra cáº¥u hÃ¬nh OpenAI API key vÃ  thá»­ láº¡i.',
          confidence: 0.0,
          sources: ['System Error'],
          conversationId,
          timestamp: new Date().toISOString(),
          category: 'service_unavailable',
          provider: 'OpenAI + RAG'
        }
      });
    }

    // Generate response using OpenAI + RAG
    const startTime = Date.now();
    let result;
    
    try {
      result = await openaiService.generateResponse(userMessage, conversationHistory);
    } catch (openaiError) {
      console.error('âŒ OpenAI + RAG call failed:', openaiError.message);
      
      return res.status(500).json({
        success: false,
        message: 'Lá»—i OpenAI + RAG API',
        data: {
          response: 'ðŸ¤– KhÃ´ng thá»ƒ káº¿t ná»‘i vá»›i há»‡ thá»‘ng AI. Vui lÃ²ng kiá»ƒm tra cáº¥u hÃ¬nh vÃ  thá»­ láº¡i sau.',
          confidence: 0.0,
          sources: ['OpenAI + RAG Error'],
          conversationId,
          timestamp: new Date().toISOString(),
          category: 'api_error',
          provider: 'OpenAI + RAG',
          error: process.env.NODE_ENV === 'development' ? openaiError.message : 'API error'
        }
      });
    }

    const processingTime = (Date.now() - startTime) / 1000;

    if (!result || !result.response) {
      console.error('âŒ Invalid response from OpenAI + RAG');
      return res.status(500).json({
        success: false,
        message: 'Pháº£n há»“i khÃ´ng há»£p lá»‡',
        data: {
          response: 'ðŸ”§ Nháº­n Ä‘Æ°á»£c pháº£n há»“i khÃ´ng há»£p lá»‡ tá»« há»‡ thá»‘ng AI. Vui lÃ²ng thá»­ láº¡i.',
          confidence: 0.0,
          sources: ['Response Error'],
          conversationId,
          timestamp: new Date().toISOString(),
          category: 'invalid_response',
          provider: 'OpenAI + RAG'
        }
      });
    }

    console.log('âœ… OpenAI + RAG response generated:', {
      responseLength: result.response.length,
      tokensUsed: result.tokensUsed,
      processingTime: `${processingTime}s`,
      model: result.model,
      ragDocsFound: result.rag_docs_found,
      confidence: result.confidence
    });

    // Update conversation history
    const updatedHistory = [
      ...conversationHistory,
      { role: 'user', content: userMessage },
      { role: 'assistant', content: result.response }
    ];

    if (updatedHistory.length > 20) {
      updatedHistory.splice(0, updatedHistory.length - 20);
    }

    conversations.set(conversationId, updatedHistory);

    // Return successful response
    return res.json({
      success: true,
      message: 'TÆ° váº¥n thÃ nh cÃ´ng vá»›i OpenAI + RAG',
      data: {
        response: result.response,
        confidence: result.confidence,
        sources: result.sources,
        conversationId,
        timestamp: new Date().toISOString(),
        category: 'openai_rag_success',
        processingTime,
        tokensUsed: result.tokensUsed,
        model: result.model,
        provider: result.provider,
        rag_documents_found: result.rag_docs_found,
        legal_context_used: result.rag_docs_found > 0
      }
    });

  } catch (error) {
    console.error('âŒ Unexpected chatbot error:', error);

    return res.status(500).json({
      success: false,
      message: 'Lá»—i há»‡ thá»‘ng khÃ´ng mong muá»‘n',
      data: {
        response: 'ðŸ’¥ ÄÃ£ xáº£y ra lá»—i khÃ´ng mong muá»‘n. Vui lÃ²ng thá»­ láº¡i hoáº·c liÃªn há»‡ há»— trá»£ ká»¹ thuáº­t.',
        confidence: 0.0,
        sources: ['System Error'],
        conversationId: req.body.conversation_id || `conv_error_${Date.now()}`,
        timestamp: new Date().toISOString(),
        category: 'unexpected_error',
        provider: 'OpenAI + RAG',
        error: process.env.NODE_ENV === 'development' ? error.message : 'Unexpected system error'
      }
    });
  }
};

// Enhanced health check
const health = async (req, res) => {
  try {
    const openaiStatus = openaiService.isHealthy();
    const ragStatus = ragService.isHealthy();
    const conversationCount = conversations.size;
    const ragStats = ragService.getStats();

    const overallHealth = openaiStatus && ragStatus;

    const response = {
      success: overallHealth,
      data: {
        status: overallHealth ? 'healthy' : 'degraded',
        service_type: 'OpenAI + RAG Enhanced',
        openai_service: {
          healthy: openaiStatus,
          model: process.env.OPENAI_MODEL || 'gpt-3.5-turbo',
          api_key_configured: !!process.env.OPENAI_API_KEY
        },
        rag_service: {
          healthy: ragStatus,
          ...ragStats
        },
        conversations: {
          active: conversationCount,
          total_messages: Array.from(conversations.values())
            .reduce((sum, history) => sum + history.length, 0)
        },
        timestamp: new Date().toISOString()
      }
    };

    res.status(overallHealth ? 200 : 503).json(response);

  } catch (error) {
    console.error('âŒ Health check error:', error);
    res.status(500).json({
      success: false,
      message: 'Health check failed',
      error: error.message
    });
  }
};

// Get conversation history
const getConversation = async (req, res) => {
  try {
    const { conversation_id } = req.params;
    const history = conversations.get(conversation_id) || [];
    
    res.json({
      success: true,
      data: {
        conversation_id,
        message_count: history.length,
        messages: history,
        provider: 'OpenAI + RAG',
        timestamp: new Date().toISOString()
      }
    });
  } catch (error) {
    res.status(500).json({
      success: false,
      message: 'Failed to retrieve conversation',
      error: error.message
    });
  }
};

// Clear conversation
const clearConversation = async (req, res) => {
  try {
    const { conversation_id } = req.body;
    const existed = conversations.has(conversation_id);
    conversations.delete(conversation_id);
    
    res.json({
      success: true,
      message: existed ? 'Conversation cleared' : 'Conversation not found',
      data: { conversation_id, existed, timestamp: new Date().toISOString() }
    });
  } catch (error) {
    res.status(500).json({
      success: false,
      message: 'Failed to clear conversation',
      error: error.message
    });
  }
};

// Get statistics
const getStats = async (req, res) => {
  try {
    const ragStats = ragService.getStats();
    const totalConversations = conversations.size;
    const allHistories = Array.from(conversations.values());
    const totalMessages = allHistories.reduce((sum, history) => sum + history.length, 0);

    res.json({
      success: true,
      data: {
        service_info: {
          type: 'OpenAI + RAG Enhanced',
          provider: 'OpenAI + FAISS',
          model: process.env.OPENAI_MODEL || 'gpt-3.5-turbo'
        },
        rag_service: ragStats,
        conversations: {
          total: totalConversations,
          total_messages: totalMessages,
          average_per_conversation: totalConversations > 0 ? Math.round(totalMessages / totalConversations) : 0
        },
        performance: {
          openai_healthy: openaiService.isHealthy(),
          rag_healthy: ragService.isHealthy(),
          uptime: process.uptime()
        },
        timestamp: new Date().toISOString()
      }
    });
  } catch (error) {
    res.status(500).json({
      success: false,
      message: 'Failed to retrieve statistics',
      error: error.message
    });
  }
};

console.log('âœ… Enhanced chatbot controller with OpenAI + RAG loaded');

module.exports = {
  chat,
  health,
  getConversation,
  clearConversation,
  getStats
};