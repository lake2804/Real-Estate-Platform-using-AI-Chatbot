from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import json
import uuid
from datetime import datetime
import logging
import os
from dotenv import load_dotenv
import traceback

# Load environment variables
load_dotenv()

app = FastAPI(title="Real Estate RAG Chatbot API", version="1.0.0")

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=os.getenv("CORS_ORIGINS", "http://localhost:3000,http://localhost:4000").split(","),
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Request/Response models
class ChatRequest(BaseModel):
    query: str
    conversation_id: Optional[str] = None
    user_id: Optional[str] = None
    context: Optional[Dict[str, Any]] = None

class ChatResponse(BaseModel):
    answer: str
    confidence: float
    sources: List[str]
    conversation_id: str
    timestamp: str

class ConversationHistory(BaseModel):
    messages: List[Dict[str, Any]]
    conversation_id: str

# In-memory storage for conversations (use Redis/DB in production)
conversations = {}

# Logging setup
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Update the chat endpoint with better error handling
@app.post("/chat", response_model=ChatResponse)
async def chat_with_rag(request: ChatRequest):
    """Main chat endpoint that processes user queries using RAG"""
    try:
        logger.info(f"ğŸ¤– Processing chat request: {request.query[:50]}...")
        logger.info(f"ğŸ“‹ Request details: conversation_id={request.conversation_id}, user_id={request.user_id}")
        
        # Generate conversation ID if not provided
        conversation_id = request.conversation_id or str(uuid.uuid4())
        
        # Initialize conversation if new
        if conversation_id not in conversations:
            conversations[conversation_id] = {
                "messages": [],
                "created_at": datetime.now().isoformat(),
                "user_id": request.user_id
            }
            logger.info(f"âœ… New conversation created: {conversation_id}")
        
        # Add user message to conversation
        user_message = {
            "role": "user",
            "content": request.query,
            "timestamp": datetime.now().isoformat()
        }
        conversations[conversation_id]["messages"].append(user_message)
        logger.info(f"âœ… User message added to conversation")
        
        # Process query with RAG system
        logger.info(f"ğŸ”„ Processing RAG query...")
        rag_result = await process_rag_query(
            query=request.query,
            context=request.context or {},
            conversation_history=conversations[conversation_id]["messages"]
        )
        logger.info(f"âœ… RAG query processed successfully")
        
        # Add bot response to conversation
        bot_message = {
            "role": "assistant",
            "content": rag_result["answer"],
            "timestamp": datetime.now().isoformat(),
            "confidence": rag_result["confidence"],
            "sources": rag_result["sources"]
        }
        conversations[conversation_id]["messages"].append(bot_message)
        
        response = ChatResponse(
            answer=rag_result["answer"],
            confidence=rag_result["confidence"],
            sources=rag_result["sources"],
            conversation_id=conversation_id,
            timestamp=datetime.now().isoformat()
        )
        
        logger.info(f"âœ… Response created successfully")
        return response
        
    except Exception as e:
        error_msg = str(e)
        error_trace = traceback.format_exc()
        logger.error(f"âŒ Chat processing error: {error_msg}")
        logger.error(f"âŒ Full traceback: {error_trace}")
        
        # Return fallback response instead of raising HTTPException
        return ChatResponse(
            answer="Xin lá»—i, tÃ´i Ä‘ang gáº·p váº¥n Ä‘á» ká»¹ thuáº­t. Vui lÃ²ng thá»­ láº¡i sau hoáº·c liÃªn há»‡ hotline 1900 1000 Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£ trá»±c tiáº¿p.",
            confidence=0.0,
            sources=[],
            conversation_id=request.conversation_id or str(uuid.uuid4()),
            timestamp=datetime.now().isoformat()
        )

# Update process_rag_query with better error handling
async def process_rag_query(query: str, context: Dict, conversation_history: List) -> Dict:
    """Process RAG query with enhanced error handling"""
    try:
        logger.info(f"ğŸ” Processing query: '{query}'")
        
        # Convert query to lowercase for matching
        query_lower = query.lower().strip()
        logger.info(f"ğŸ” Query lowercase: '{query_lower}'")
        
        # Check for greeting words
        greeting_words = ["xin chÃ o", "hello", "hi", "chÃ o", "xin", "chao"]
        if any(word in query_lower for word in greeting_words):
            logger.info("âœ… Matched greeting pattern")
            answer = """
ğŸ‘‹ **Xin chÃ o! TÃ´i lÃ  AI Assistant chuyÃªn vá» báº¥t Ä‘á»™ng sáº£n.**

ğŸ¯ **TÃ´i cÃ³ thá»ƒ giÃºp báº¡n:**
ğŸ  TÃ¬m kiáº¿m cÄƒn há»™, nhÃ  Ä‘áº¥t phÃ¹ há»£p
ğŸ’° TÆ° váº¥n giÃ¡ cáº£ vÃ  xu hÆ°á»›ng thá»‹ trÆ°á»ng
ğŸ—ï¸ ThÃ´ng tin cÃ¡c dá»± Ã¡n má»›i nháº¥t  
ğŸ“‹ HÆ°á»›ng dáº«n thá»§ tá»¥c mua bÃ¡n
ğŸ“ˆ PhÃ¢n tÃ­ch cÆ¡ há»™i Ä‘áº§u tÆ°

**CÃ¢u há»i phá»• biáº¿n:**
â€¢ "GiÃ¡ nhÃ  khu vá»±c Quáº­n 7 nhÆ° tháº¿ nÃ o?"
â€¢ "Dá»± Ã¡n nÃ o Ä‘ang má»Ÿ bÃ¡n tá»‘t nháº¥t?"
â€¢ "TÆ° váº¥n mua cÄƒn há»™ Ä‘áº§u tÆ° vá»›i 3 tá»·"

ğŸ’¬ **Báº¡n quan tÃ¢m vá» Ä‘iá»u gÃ¬? HÃ£y há»i tÃ´i nhÃ©!**
            """
            confidence = 0.95
            sources = ["Chatbot Greeting"]
            
        # Check for price-related words
        elif any(word in query_lower for word in ["giÃ¡", "price", "bÃ¡n", "mua", "cost", "money"]):
            logger.info("âœ… Matched price pattern")
            answer = """
ğŸ  **ThÃ´ng tin giÃ¡ báº¥t Ä‘á»™ng sáº£n hiá»‡n táº¡i:**

**CÄƒn há»™ chung cÆ° TP.HCM:**
â€¢ Quáº­n 1, 3: 60-120 triá»‡u/mÂ²
â€¢ Quáº­n 2, 7, 9: 40-70 triá»‡u/mÂ²  
â€¢ Quáº­n ngoáº¡i: 25-45 triá»‡u/mÂ²

**NhÃ  riÃªng:**
â€¢ Trung tÃ¢m: 150-400 triá»‡u/mÂ²
â€¢ Ngoáº¡i thÃ nh: 80-150 triá»‡u/mÂ²

**Xu hÆ°á»›ng thá»‹ trÆ°á»ng Q4/2024:**
ğŸ“ˆ GiÃ¡ tÄƒng 6-8%/nÄƒm
ğŸ—ï¸ Nguá»“n cung khan hiáº¿m khu trung tÃ¢m
ğŸ’¡ Khu ÄÃ´ng (Q2, Q9, Thá»§ Äá»©c) phÃ¡t triá»ƒn máº¡nh

Báº¡n quan tÃ¢m khu vá»±c nÃ o cá»¥ thá»ƒ?
            """
            confidence = 0.88
            sources = ["BÃ¡o cÃ¡o thá»‹ trÆ°á»ng BÄS Q4/2024"]
            
        # Check for project-related words
        elif any(word in query_lower for word in ["dá»± Ã¡n", "project", "chung cÆ°", "vinhomes", "masteri", "apartment"]):
            logger.info("âœ… Matched project pattern")
            answer = """
ğŸ—ï¸ **TOP dá»± Ã¡n ná»•i báº­t Ä‘ang má»Ÿ bÃ¡n:**

**ğŸŒŸ Vinhomes Grand Park - Quáº­n 9**
â€¢ GiÃ¡: 35-50 triá»‡u/mÂ²
â€¢ Tiáº¿n Ä‘á»™: Äang bÃ n giao T1-T5
â€¢ Æ¯u Ä‘iá»ƒm: CÃ´ng viÃªn 36ha, trÆ°á»ng quá»‘c táº¿

**ğŸŒŸ Masteri Centre Point - Quáº­n 9**
â€¢ GiÃ¡: 42-58 triá»‡u/mÂ²
â€¢ Tiáº¿n Ä‘á»™: HoÃ n thiá»‡n Q3/2025
â€¢ Æ¯u Ä‘iá»ƒm: View sÃ´ng, gáº§n Metro Line 1

**ğŸŒŸ The Metropole Thá»§ ThiÃªm - Quáº­n 2**
â€¢ GiÃ¡: 70-110 triá»‡u/mÂ²
â€¢ Tiáº¿n Ä‘á»™: Sáº¯p má»Ÿ bÃ¡n Q1/2025
â€¢ Äáº·c Ä‘iá»ƒm: Háº¡ng sang, view Landmark 81

Báº¡n muá»‘n tÃ¬m hiá»ƒu dá»± Ã¡n nÃ o chi tiáº¿t?
            """
            confidence = 0.92
            sources = ["Website chá»§ Ä‘áº§u tÆ°", "ThÃ´ng tin mÃ´i giá»›i"]
            
        # Check for advice-related words
        elif any(word in query_lower for word in ["tÆ° váº¥n", "advice", "Ä‘áº§u tÆ°", "nÃªn", "recommend", "suggest"]):
            logger.info("âœ… Matched advice pattern")
            answer = """
ğŸ’¡ **TÆ° váº¥n Ä‘áº§u tÆ° báº¥t Ä‘á»™ng sáº£n 2024:**

**ğŸ” PHÃ‚N TÃCH THá»Š TRÆ¯á»œNG:**
ğŸ“Š Thá»‹ trÆ°á»ng Ä‘Ã£ qua Ä‘Ã¡y, Ä‘ang há»“i phá»¥c
ğŸ’° LÃ£i suáº¥t ngÃ¢n hÃ ng á»•n Ä‘á»‹nh 10-12%/nÄƒm
ğŸ—ï¸ Nguá»“n cung má»›i háº¡n cháº¿, giÃ¡ tÄƒng nháº¹

**â­ KHU Vá»°C ÄÃNG Äáº¦U TÆ¯:**
â€¢ Khu ÄÃ´ng (Q2, Q9, Thá»§ Äá»©c): Tiá»m nÄƒng cao
â€¢ Khu Nam (Q7, NhÃ  BÃ¨): Thanh khoáº£n tá»‘t

**ğŸ’¡ LOOS KHUYÃŠN:**
âœ… Æ¯u tiÃªn vá»‹ trÃ­ cÃ³ tiá»m nÄƒng phÃ¡t triá»ƒn
âœ… Gáº§n giao thÃ´ng cÃ´ng cá»™ng
âœ… Khu vá»±c cÃ³ trÆ°á»ng há»c tá»‘t
âœ… KhÃ´ng vay quÃ¡ 70% giÃ¡ trá»‹ nhÃ 

Báº¡n cÃ³ bao nhiÃªu vá»‘n vÃ  muá»‘n Ä‘áº§u tÆ° theo hÆ°á»›ng nÃ o?
            """
            confidence = 0.90
            sources = ["PhÃ¢n tÃ­ch chuyÃªn gia", "BÃ¡o cÃ¡o thá»‹ trÆ°á»ng"]
            
        # Check for rental-related words
        elif any(word in query_lower for word in ["thuÃª", "rent", "cho thuÃª", "rental"]):
            logger.info("âœ… Matched rental pattern")
            answer = """
ğŸ  **Thá»‹ trÆ°á»ng cho thuÃª TP.HCM 2024:**

**ğŸ’° GIÃ THUÃŠ HIá»†N Táº I:**
â€¢ Studio/1PN: 8-18 triá»‡u/thÃ¡ng
â€¢ 2PN: 15-30 triá»‡u/thÃ¡ng  
â€¢ 3PN: 22-45 triá»‡u/thÃ¡ng

**ğŸ”¥ KHU Vá»°C HOT CHO THUÃŠ:**
â€¢ Quáº­n 1, 3, 5: GiÃ¡ cao, dá»… cho thuÃª
â€¢ Quáº­n 2, 7, 9: GiÃ¡ trung bÃ¬nh, cÃ¢n báº±ng tá»‘t

**ğŸ’¡ TIPS CHO THUÃŠ NHANH:**
ğŸ“¸ Chá»¥p áº£nh chuyÃªn nghiá»‡p
ğŸ’° GiÃ¡ cáº¡nh tranh vá»›i thá»‹ trÆ°á»ng
ğŸ“± ÄÄƒng Ä‘a kÃªnal: Batdongsan, Chotot

Báº¡n Ä‘ang muá»‘n cho thuÃª hay tÃ¬m thuÃª nhÃ ?
            """
            confidence = 0.87
            sources = ["Thá»‘ng kÃª cho thuÃª", "Kinh nghiá»‡m mÃ´i giá»›i"]
            
        else:
            # Default response for any other query
            logger.info("âœ… Using default response")
            answer = """
ğŸ¤” **TÃ´i chÆ°a hiá»ƒu rÃµ cÃ¢u há»i cá»§a báº¡n. Äá»ƒ tÃ´i cÃ³ thá»ƒ há»— trá»£ tá»‘t hÆ¡n:**

**ğŸ  CÃC CHá»¦ Äá»€ TÃ”I CÃ“ THá»‚ TÆ¯ Váº¤N:**

ğŸ“Š **ThÃ´ng tin thá»‹ trÆ°á»ng:**
â€¢ "GiÃ¡ nhÃ  á»Ÿ khu vá»±c [tÃªn quáº­n]"
â€¢ "Xu hÆ°á»›ng giÃ¡ báº¥t Ä‘á»™ng sáº£n 2024"

ğŸ—ï¸ **Dá»± Ã¡n báº¥t Ä‘á»™ng sáº£n:**
â€¢ "Dá»± Ã¡n nÃ o Ä‘ang má»Ÿ bÃ¡n tá»‘t?"
â€¢ "ThÃ´ng tin vá» dá»± Ã¡n Vinhomes"

ğŸ’¡ **TÆ° váº¥n Ä‘áº§u tÆ°:**
â€¢ "NÃªn Ä‘áº§u tÆ° khu vá»±c nÃ o?"
â€¢ "Mua nhÃ  vá»›i 3 tá»· nÃªn chá»n tháº¿ nÃ o?"

ğŸ  **ThuÃª nhÃ :**
â€¢ "GiÃ¡ thuÃª cÄƒn há»™ 2PN á»Ÿ Quáº­n 7"

**ğŸ’¬ VÃ Dá»¤ CÃ‚U Há»I:**
â€¢ "TÆ° váº¥n mua cÄƒn há»™ 2PN giÃ¡ 3 tá»·"
â€¢ "GiÃ¡ thuÃª nhÃ  riÃªng á»Ÿ Quáº­n 2"

Báº¡n cÃ³ thá»ƒ há»i cá»¥ thá»ƒ hÆ¡n khÃ´ng?
            """
            confidence = 0.70
            sources = ["HÆ°á»›ng dáº«n sá»­ dá»¥ng"]
        
        result = {
            "answer": answer.strip(),
            "confidence": confidence,
            "sources": sources
        }
        
        logger.info(f"âœ… RAG result created: confidence={confidence}")
        return result
        
    except Exception as e:
        error_msg = str(e)
        error_trace = traceback.format_exc()
        logger.error(f"âŒ RAG processing error: {error_msg}")
        logger.error(f"âŒ RAG traceback: {error_trace}")
        
        return {
            "answer": "Xin lá»—i, tÃ´i Ä‘ang gáº·p váº¥n Ä‘á» ká»¹ thuáº­t. Vui lÃ²ng thá»­ láº¡i sau hoáº·c liÃªn há»‡ hotline 1900 1000.",
            "confidence": 0.0,
            "sources": []
        }

@app.get("/history/{conversation_id}", response_model=ConversationHistory)
async def get_conversation_history(conversation_id: str):
    """Get conversation history"""
    if conversation_id not in conversations:
        raise HTTPException(status_code=404, detail="Conversation not found")
    
    return ConversationHistory(
        messages=conversations[conversation_id]["messages"],
        conversation_id=conversation_id
    )

@app.delete("/clear/{conversation_id}")
async def clear_conversation(conversation_id: str):
    """Clear conversation history"""
    if conversation_id in conversations:
        del conversations[conversation_id]
    
    return {"message": "Conversation cleared successfully"}

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "active_conversations": len(conversations),
        "python_version": "3.x",
        "service": "Real Estate RAG Chatbot"
    }

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8001))
    host = os.getenv("HOST", "0.0.0.0")
    uvicorn.run(app, host=host, port=port)